# Доказательства-хуй-незнакомке-в-общественном-месте-показательства

### 1. Сформулировать и доказать теорему о методе Гаусса

Всякую конечную матрицу можно с помощью элементарных образований к ступенчатому виду.

#### Доказательство

$\square$ Предъявим алгоритм. Фиксируем текущий элемент в левом верхнем углу ($a_{11}$).

$1)$ Если текущей элемент равен нулю, переходим к пункту $2$. Иначе называем текущий элемент ($a_{ij}$) ведущим. Используя ведущую строку добиваемся того, чтобы все элементы ниже и выше $a_{ij}$ были равны $0$, а на месте $a_{ij}$ стояла единица:

$$\forall k \neq j \Rightarrow A_k := A_k - A_j \frac{a_{kj}}{a_{ij}} \\
A_i := A_i \frac{1}{a_{ij}}$$

Выбираем новый текущий элемент, смещаясь в матрице на столбец вправо и на строку вниз.

$2)$ Если текущий элемент равен $0$, то просматриваем все элементы под ним. Если среди них существует ненулевой, меняем местами строку, содержащую ненулевой элемент, с текущей, иначе переходим к пунту $3)$.

$3)$ Если текущий элемент и все под ним равны $0$, то смещаемся на столбец вправо и переходим к пункту $1)$.

В том случае, когда мы достигли последнего столбца, прекращаем работу алгоритма.

Так как матрица конечна, то за конечное число шагов алгоритм завершит работу, приведя матрицу к ступенчатому (каноническому) виду. $\blacksquare$

### 2. Выписать формулы крамера для квадратной матрицы произвольного порядка и доказать их (предполагается, что решение существует, а свойства определителя известны)

Для системы $A X = B$

$x_k = \frac{\Delta_k}{\Delta}$, где $\Delta$ — определитель матрицы $A$, а $\Delta_i$ — определитель матрицы, получаемой из матрицы $A$ заменой $i$-го столбца на $B$.



$\square$ Т. к. $\Delta \neq 0$, матрица $A$ обратима, следовательно

$$
X = A^{-1}B = \frac{1}{\det A} \left( 
\begin{array}{cccc}
A_{11} & A_{21} & \dots & A_{n1} \\
A_{12} & A_{22} & \dots & A_{n2} & \\
\vdots & \vdots & \ddots & \vdots &  \\
A_{1n} & A_{2n} & \dots & A_{nn} & 
\end{array}
 \right) \left(
\begin{array}{c}
b_1 \\
b_2 \\
\vdots \\
b_n
\end{array}
\right),
$$

откуда

$$
x_k = \frac{1}{\det A} \sum^n_{i=1} A_{ik} b_i = \frac{1}{\det A} (b_1 A_{1k} + b_2 A_{2k} + \dots + b_n A_{nk}), \\
k = 1, 2, \dots, n.
$$

Разложив $\Delta_k$ по $k$-му столбцу, получаем:

$$
\Delta_k = b_1 A_{1k} + b_2 A_{2k} + \dots + b_n A_{nk},
$$

следовательно

$$
x_k = \frac{\Delta_k}{\Delta}. \blacksquare
$$

### 3. Дать определение обратной матрицы. Сформулировать и доказать критерий существования обратной матрицы. Единственна ли обратная матрица? Ответ обосновать.

$A^{-1}$ — обратная к $A$, если

$$
A^{-1} A = A A^{-1} = E.
$$

Обратная матрица единственна. 

$\square$ Допустим, $A^{-1}$ и $\widetilde{A^{-1}}$ — две разные обратные матрицы к матрице $A$. Тогда в силу ассоциативности

$$
 A^{-1}  = A^{-1} E = A^{-1} A \widetilde{A^{-1}} = E \widetilde{A^{-1}} = \widetilde{A^{-1}},
$$

откуда

$$
A^{-1} = \widetilde{A^{-1}}.
$$

Пришли к противоречию. $\blacksquare$

Матрица обратима тогда и только тогда, когда она невырождена (ее определитель не равен нулю).

$\square$ $1)$ См. вопрос 4.

$2)$ Допустим, $A A^{-1} = E$. Тогда

$$
\det A A^{-1} = \det A \det A^{-1} = \det E = 1 \neq 0,
$$

следовательно, 

$$
\det A \neq 0. \blacksquare
$$

### 4. Выписать формулу для нахождения обратной матрицы и доказать её.

$$
A^{-1} = \frac{1}{|A|} A^*,
$$

где $A^*$ — союзная матрица.

$\square$ Допустим, $|A| \neq 0$. Построим союзную матрицу к $A$:

$$
A^* = \left(
\begin{array}{cccc}
A_{11} & A_{21} & \dots & A_{n1} & \\
A_{12} & A_{22} & \dots & A_{n2} & \\
\vdots & \vdots & \ddots & \vdots & \\
A_{1n} & A_{2n} & \dots & A_{nn} & \\
\end{array}
\right).
$$

Найдем элементы матрицы $A A^* = (b_{ij})$:

$$
b_{ij} = a_{i1} A_{j1} + a_{i2} A_{j2} + \dots + a_{in} A_{jn}.
$$

Легко видеть, что $b_{ii}$ — разложение $|A|$ по $i$-й строке, а $b_{ij}$ (при $i \neq j$) — фальшивое разложение, следовательно

$$
A A^* = \left(
\begin{array}{cccc}
|A| & 0 & \dots & 0 \\
0 & |A| & \dots & 0 \\
\vdots & \vdots & \ddots & \vdots & \\
0 & 0 & \dots & |A| \\ 
\end{array}
\right) = |A| E.
$$

Повторяя аналогичные рассуждения для матрицы $A^* A$, получаем

$$
A A^* = A^* A = |A| E
$$

откуда, т. к. $|A| \neq 0$, следует

$$
A \left( \frac{1}{|A|} A^* \right) = \left( \frac{1}{|A|} A^* \right) A = E,
$$

следовательно,

$$
\frac{1}{|A|} A^* = \frac{1}{|A|} A^* = A^{-1}.
$$

###5. Сформулировать критерий линейной зависимости и доказать его.

Система векторов линейно зависима тогда и только тогда, когда один из векторов линейно выражается через другие.

$\square$ $1)$ Допустим,

$$
v_n = \alpha_1 v_1 + \alpha_2 v_2 + \dots + \alpha_{n-1} v_{n-1},
$$

тогда

$$
\alpha_1 v_1 + \alpha_2 v_2 + \dots + \alpha_{n-1} v_{n-1} - v_n = 0,
$$

следовательно, система векторов $v_1, v_2, \dots, v_n$ линейно зависима, т. к. в разложении нуля есть хотя бы один ненулевой коэфициент ($-1$ при $v_n$).

$2)$ Допустим, система векторов $v_1, v_2, \dots, v_n$ линейно зависима. Тогда 

$$
\alpha_1 v_1 + \alpha_2 v_2 + \dots + \alpha_{n-1} v_{n-1} + \alpha_n v_n = 0,
$$

и хотя бы один из $\alpha_1, \dots, \alpha_n$ не равен нулю. Допустим, $\alpha_n \neq 0$. Тогда

$$
v_n = \frac{\alpha_1}{\alpha_n} v_1 + \frac{\alpha_2}{\alpha_n} v_2 + \dots + \frac{\alpha_{n-1}}{\alpha_n} v_{n-1}. \blacksquare
$$

###6. Дать определение ранга. Как он меняется при транспонировании? Ответ обосновать, используя только определение.

Ранг матрицы — это порядок ее базисного минора. (Определение Chernyshew-style — прим. г.)

Минор называется базисным, если он ненулевой и имеет порядок $i$, а все миноры порядка $i+1$ нулевые или не существуют.

При транспонировании ранг матрицы не меняется.

$\square$ Допустим, матрица $A$ порядка имеет ненулевой базисный минор $M = \det A^{i_1, \dots, i_k}_{j_1, \dots, j_k}$. Тогда матрица $A^T$ будет иметь базисный минор $\widetilde{M} = \det (A^T)^{i_1, \dots, i_k}_{j_1, \dots, j_k} = \det A^{j_1, \dots, j_k}_{i_1, \dots, i_k}$.

Легко видеть, что минор $\widetilde{M}$ отличается от $M$ операцией транспонирования. Так как при транспонировании определитель не меняется, их определители оба ненулевые. Следовательно,
$$
\text{rank} A^T \ge \text{rank} A.
$$

Повторяя рассуждения, получаем

$$
\text{rank} A = \text{rank} (A^T)^T \ge \text{rank} A^T \ge \text{rank}A,
$$

а следовательно, 

$$
\text{rank} A^T = \text{rank} A. \blacksquare
$$

### 7. Сформулировать и доказать критерий невырожденности квадратной матрицы, использующий понятие ранга (теорема о базисном миноре предполагается известной)

Квадратная матрица невырождена тогда и только тогда, когда ее ранг равен ее размерности.

$\square$ Рассмотрим квадратную матрицу размерности $n$.

$1)$ Допустим, матрица невырождена. В качестве базисного минора возьмем определитель всей матрицы. Размерность этого базисного минора равна $n$. Так как ранг — это размерность базисного минора, в таком случае ранг также равен $n$.

$2)$ Допустим, ранг матрицы равен $n$. Значит, размерность базисного минора также равна $n$, следовательно, базисный минор равен определителю матрицы. Так как минор ненулевой, определитель матрицы тоже ненулевой, и матрица невырождена. $\blacksquare$

### 8. Выписать свойства решений однородных и неоднородных СЛАУ (линейная комбинация решений однородной СЛАУ является решением однородной СЛАУ, разность двух решений неоднородной СЛАУ есть решение однородной СЛАУ, сумма решения однородной СЛАУ и решения неоднородной СЛАУ есть решение неоднородной СЛАУ) и доказать их.

Линейная комбинация решений однородной СЛАУ является решением однородной СЛАУ.

$\square$ Допустим, $A X_1 = 0$, и $A X_2 = 0$. Тогда

$$
A (\alpha X_1 + \beta X_2) = \alpha A X_1 + \beta A X_2 = 0. \blacksquare
$$

Разность двух решений неоднородной СЛАУ есть решение однородной СЛАУ.

$\square$ Допустим, $A X_1 = B$, и $A X_2 = B$. Тогда

$$
A (X_1 - X_2) = A X_1 - A X_2 = B - B = 0. \blacksquare
$$

Сумма решения однородной СЛАУ и решения неоднородной СЛАУ есть решение неоднородной СЛАУ.

$\square$ Допустим, $A X_1 = 0$, и $A X_2 = B$. Тогда

$$
A (X_1 + X_2) = A X_1 + A X_2 = 0 + B = B. \blacksquare
$$

### 9. Сформулировать теорему Кронекера-Капелли и доказать её.

СЛАУ совместна тогда и только тогда, когда ранг ее основной матрицы равен рангу расширенной.

$\square$ $1)$ Если система $A \begin{pmatrix} x_1\\ \vdots \\ x_n \end{pmatrix} = B$ совместна, то вектор $B$ — линейная комбинация векторов-столбцов матрицы $A$ с коэффициентами $x_1, \dots, x_n$, следовательно, количество линейно независимых столбцов в матрицах $A$ и $A|B$ одинаковое.

Так как ранг матрицы равен количеству линейно независимых столбцов, 

$$
\text{rank} A = \text{rank} (A|B).
$$

$2)$ Допустим $\{ A^1, \dots, A^j \}$ — максимальный линейно независимый набор столбцов матрицы $A$. Т. к. $\text{rank} A = \text{rank} (A|B)$, набор $\{ A^1, \dots, A^j, B \}$ будет уже линейно зависимым. Следовательно (там по одной теореме у Кострикина), $B$ — линейная комбинация векторов $A^1, \dots, A^j$. $\blacksquare$

### 10. Сформировать критерий существования ненулевого решения однородной системы линейных уравнений с квадратной матрицей и доказать его.

Однородная СЛАУ с квадратной матрицей имеет ненулевое решение тогда и только тогда, когда ее матрица вырождена.

$\square$ Существование ненулевого решения у системы $AX = 0$ равносильно существованию разложения нулевого вектора на векторы-столбцы матрицы $A$ с ненулевыми коэфициентами. Другими словами, ненулевое решение существует тогда, когда столбцы матрицы $A$ линейно зависимы.

По теореме о базисном миноре, столбы базисного минора линейно независимы и другие столбы матрицы является линейными комбинациями столбцов базисного минора. Вследствие этого,

$1)$ Если столбцы линейно зависимы, определитель матрицы $A$ не является базисным минором и равен нулю — матрица вырождена.

$2)$ Если матрица вырождена — ее определитель равен нулю, тогда он не является базисным минором и какие-то из столбцов матрицы линейно выражаются через другие — столбцы матрицы линейно зависимы. $\blacksquare$

### 11. Дать определение фундаментальной системы решений (ФСР) однородной системы решений. Доказать теорему о существовании ФСР.

Любой набор из $n - r$ линейно независимых решений СЛАУ $AX = 0$, где $n$ — кол-во неизвестных, $r = \text{rank} A$.

Пусть дана СЛАУ $AX = 0$ с $n$ неизвестными и $\text{rank} A = r$. Тогда существует набор из $k = n - r$ решений $x^{(1)}, \dots, x^{(k)}$ этой СЛАУ, образующих ФСР.

$\square$ Будем считать, что базисный минор матрицы $A$ находится в левом верхнем углу, т.е. в столбцах $1, \dots, r$ и строках $1, \dots, r$.

По теореме о базисном миноре уравнения с $r + 1$ по $n$ являются линейными комбинация первых $r$ уравнений. Значит, их можно отбросить без изменения решения системы. Получаем систему

$$
\begin{cases}
    a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = 0 \\
    a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n = 0\\
    \dots \\
    a_{r1}x_1 + a_{r2}x_2 + \dots + a_{rn}x_n = 0. \\
\end{cases}
$$

Разделим переменные на базисные $x_1, \dots, x_r$ и свободные $x_{r+1}, \dots, x_n$. Перенесем свободные в правую часть:

$$
\begin{cases}
    a_{11}x_1 + \dots + a_{1r}x_r = - a_{1(r+1)} x_{r+1} - \dots - a_{1n} x_n \\
    a_{21}x_1 + \dots + a_{2r}x_r = - a_{2(r+1)} x_{r+1} - \dots - a_{2n} x_n \\
    \dots \\
    a_{r1}x_1 + \dots + a_{rr}x_r = - a_{r(r+1)} x_{r+1} - \dots - a_{rn} x_n. \\
\end{cases}
$$

Если мы присвоим произвольные значения свободным переменным, то относительно базисных мы получим квадратную СЛАУ с невырожденной матрицей, решение которой существует и единственно. Таким образом, решение исходной СЛАУ однозначно определяется значениями свободных неизвестных $x_{r+1}, \dots, x_n$. Рассмотрим следующие $k = n - r$ серий значений свободных неизвестных:

$$
\begin{array}
& x^{(1)}_{r+1} = 1,  & x^{(2)}_{r+1} = 0, & \dots & x^{(k)}_{r+1} = 0, \\
x^{(1)}_{r+2} = 0, & x^{(2)}_{r+} = 1, & \dots & x^{(k)}_{r+2} = 0, \\
\vdots & \vdots & \ddots & \vdots & \\
x^{(1)}_n = 0, & x^{(2)}_n = 0, & \dots & x^{(k)}_n = 1.
\end{array}
$$

$i$-й серии значений серии значений свободных переменных однозначно соответствуют значения $x_1^{(i)}, \dots, x_r^{(i)}$ базисных. Покажем, что столбцы:

$$
x^{(i)} = \begin{pmatrix}
x^{(i)}_1\\
\vdots \\
x^{(i)}_n
\end{pmatrix}, i = \overline{1, k}
$$

образуют ФСР. Т. к. эти столбцы по построению являются решениями системы $AX = B$ и их количество равно $k = n - r$, остается доказать их линейную независимость.

Допустим, существуют $\alpha_1, \dots, \alpha_k такие, что$

$$
\alpha_1 x^{(1)} + \dots + \alpha_k x^{(k)} = 0.
$$

Но тогда $r+1$-й элемент левого вектора равен $\alpha_1 1 + \alpha_2 0 + \dots + \alpha_k 0 = 0$, из чего следует $\alpha_1 = 0$. Повторяя рассуждения для следующих элементов, приходим к выводу, что $\alpha_1 = \dots = \alpha_k = 0$. Следовательно, система линейно независима. $\blacksquare$

#### 12. Доказать теорему о структуре общего решения однородной СЛАУ (то есть, о том, что произвольное решение однородной СЛАУ может быть представлено в виде комбинации ФСР).

Если $x^{(1)}, \dots, x^{(k)}$ — произвольная ФСР системы $AX = 0$, то любое ее решение $x$ можно представить в виде

$$
x = c_1 x^{(1)} + \dots + c_k x^{(k)}.
$$

И наоборот, любая линейная комбинация векторов ФСР будет решением этой СЛАУ.

$\square$ $1)$ Что линейная комбинация векторов ФСР является решением, следует из того, что векторы ФСР является решениями и линейная комбинация решений является решением (См. вопрос 8).

$2)$ Допустим $x$ — решение СЛАУ. Составим матрицу из столбцов ФСР и припишем к ним столбец $x$:

$$
H = \begin{pmatrix}
\phi_{11} & \dots & \phi_{1k} & x_1 \\
\phi_{21} & \dots & \phi_{2k} & x_2 \\
\vdots & \ddots & \vdots & \vdots \\
\phi_{r1} & \dots & \phi_{rk} & x_r \\
\vdots & \ddots & \vdots & \vdots \\
\phi_{n1} & \dots & \phi_{nk} & x_n \\
\end{pmatrix}.
$$

Найдем ранг этой матрицы. Т. к. первые $n - r$ столбцов линейно независимы, $\text{rank} H \ge n - r$.

# ... $\blacksquare$

#### 13. Сформулировать теорему о структуре общего решения неоднородной СЛАУ и доказать ее.

Если $x$ — решение системы $AX = B$, а $\phi^{(1)}, \dots, \phi^{(k)}$ — произвольная ФСР системы $AX = 0$, то $x$ представляется в виде:

$$
x = x^0 + c_1 \phi^{(1)} + \dots + c_k \phi^{(k)},
$$

где $x^0$ — частное решение $AX = B$.

$\square$ Т. к. $x$, $x^0$ — решения неоднородной СЛАУ, то $x - x^0$ — решение однородной:

$$
A(x - x^0) = Ax - Ax^0 = B - B = 0.
$$

А любое решение однородной СЛАУ представляется в виде линейной комбинации векторов ФСР. Следовательно, 

$$
x - x^0 = c_1 \phi^{(1)} + \dots + c_k \phi^{(k)}. \blacksquare
$$

#### 14. Выписать формулу для вычисления векторного произведения в координатах, заданных в ортонормированном базисе, и доказать ее.

$$
[a,b] = \begin{vmatrix}
\textbf{i} & \textbf{j} & \textbf{k} \\
a_x & a_y & a_z \\
b_x & b_y & b_z
\end{vmatrix}.
$$

$\square$ Докажем, что такое векторное произведение подходит под определение.

$1)$ Скалярное произведение $([a, b], a)$ равно нулю, т. к. определитель матрицы, у которой два столбца линейно зависимы, равен нулю:

$$
([a, b], a) = a_x \begin{vmatrix}
a_y & a_z \\
b_y & b_z
\end{vmatrix} - a_y \begin{vmatrix}
a_x & a_z \\
b_x & b_z
\end{vmatrix} + a_z \begin{vmatrix}
a_x & a_y \\
b_x & b_y
\end{vmatrix} = \begin{vmatrix}
a_x & a_y & a_z \\
a_x & a_y & a_z \\
b_x & b_y & b_z
\end{vmatrix}.
$$

Аналогично $([a, b], b) = 0$.

Следовательно, предложенное произведение ортогонально каждому из векторов $a, b$.

$2)$ Докажем, что $|[a,b]| = |a| |b| \sin \phi$.

$$
\cos\phi = \frac{(a,b)}{|a| |b|} \\
\sin^2 \phi = 1 - \cos^2\phi = \frac{|a|^2 |b|^2 - (a, b)^2}{|a|^2 |b|^2} \\
\sin \phi = \frac{\sqrt{|a|^2 + |b|^2 - (a, b)^2}}{|a| |b|},
$$

откуда

$$
|a| |b| \sin \phi = \sqrt{|a|^2 + |b|^2 - (a, b)^2} = \\
a_y^2 b_x^2 - 2 a_x a_y b_x b_y + a_x^2 b_y^2 + a_z^2 b_x^2 - 2 a_x a_z b_x b_z + a_x^2 b_z^2 + \\
+ a_z^2 b_y^2 - 2 a_y a_y b_y b_z + a_y^2 b_z^2.
$$

А модуль $[a,b]$

$$
|[a,b]| = |(\begin{vmatrix}
a_y & a_z \\
b_y & b_z
\end{vmatrix}, \begin{vmatrix}
a_x & a_z \\
b_x & b_z
\end{vmatrix}, \begin{vmatrix}
a_x & a_y \\
b_x & b_y
\end{vmatrix})| = \\
= |(a_y b_z - a_z b_y, a_z b_x - a_x b_z, a_x b_y - a_y b_x)|
$$

равен тому же самому. Вот так вот!

$3)$ По тому же самому свойству определителя

$$
[a, a] = \begin{vmatrix}
\textbf{i} & \textbf{j} & \textbf{k} \\
a_x & a_y & a_z \\
a_x & a_y & a_z \\
\end{vmatrix} = 0. \blacksquare
$$